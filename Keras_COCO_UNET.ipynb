{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_COCO_UNET.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-QreKZI06NT",
        "colab_type": "text"
      },
      "source": [
        "# COCO DATASET GATHERING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3DkfDsiwrpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/train2014.zip\n",
        "!unzip -q train2014.zip\n",
        "!wget http://images.cocodataset.org/zips/val2014.zip\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
        "!unzip -q val2014.zip\n",
        "!unzip -q annotations_trainval2014.zip\n",
        "\n",
        "\n",
        "! pip install 2to3\n",
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi\n",
        "!2to3 . -w\n",
        "%cd PythonAPI\n",
        "!python3 setup.py install\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT6zZ-D51LWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnF0aYFB1OXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Data From COCO\n",
        "\n",
        "from pycocotools import coco, cocoeval, _mask\n",
        "from pycocotools import mask as maskUtils \n",
        "import array\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import os\n",
        "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUWcLqnJ1SUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CATEGORY_NAMES=['person']\n",
        "\n",
        "ANNOTATION_FILE_VAL = '/content/annotations/instances_val2014.json'\n",
        "ANNOTATION_FILE_TRAIN = '/content/annotations/instances_train2014.json'\n",
        "\n",
        "\n",
        "coco_train = coco.COCO(ANNOTATION_FILE_TRAIN)\n",
        "catIds_train = coco_train.getCatIds(catNms=CATEGORY_NAMES);\n",
        "imgIds_train = coco_train.getImgIds(catIds=catIds_train);\n",
        "imgDict_train = coco_train.loadImgs(imgIds_train)\n",
        "len(imgIds_train) , len(catIds_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "coco_val = coco.COCO(ANNOTATION_FILE_VAL)\n",
        "catIds_val = coco_val.getCatIds(catNms=CATEGORY_NAMES);\n",
        "imgIds_val = coco_val.getImgIds(catIds=catIds_val);\n",
        "imgDict_val = coco_val.loadImgs(imgIds_val)\n",
        "len(imgIds_val) , len(catIds_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9akfTem1Ue-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "\n",
        "shuffle(imgIds_train)\n",
        "shuffle(imgIds_val)\n",
        "\n",
        "imgIds_train = imgIds_train[0:6000]\n",
        "imgIds_val = imgIds_val[0:600]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIktAjPp1Xs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images_person = [\"COCO_train2014_{0:012d}.jpg\".format(ids) for ids in imgIds_train]\n",
        "val_images_person = [\"COCO_val2014_{0:012d}.jpg\".format(ids) for ids in imgIds_val]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD2mRyK71bSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_images_person) , len(val_images_person))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDxYUzZT1crY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images_person = [\"COCO_train2014_{0:012d}.jpg\".format(ids) for ids in imgIds_train]\n",
        "print(train_images_person)\n",
        "del_img_train = set(os.listdir(\"/content/train2014\")) - set(train_images_person)\n",
        "for file_name in del_img_train:\n",
        "  file_name = \"/content/train2014/\" + file_name\n",
        "  if os.path.exists(file_name):\n",
        "    os.remove(file_name)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gWAno9N1dUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(os.listdir(\"/content/train2014\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAeyJbE71fUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_images_person = [\"COCO_val2014_{0:012d}.jpg\".format(ids) for ids in imgIds_val]\n",
        "print(val_images_person)\n",
        "del_img_val = set(os.listdir(\"/content/val2014\")) - set(val_images_person)\n",
        "for file_name in del_img_val:\n",
        "  file_name = \"/content/val2014/\" + file_name\n",
        "  if os.path.exists(file_name):\n",
        "    os.remove(file_name)\n",
        "\n",
        "len(os.listdir(\"/content/val2014\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyiCRQGd1hVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHhhJuEw1mvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir mask_train_2014"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W4zM_SZ1new",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = 0 \n",
        "\n",
        "for ID in imgIds_train:\n",
        "\n",
        "  file_path = \"/content/mask_train_2014/COCO_train2014_{0:012d}.jpg\".format(ID)\n",
        "  \n",
        "  sampleImgIds = coco_train.getImgIds(imgIds = [ID])\n",
        "  sampleImgDict = coco_train.loadImgs(sampleImgIds[np.random.randint(0,len(sampleImgIds))])[0]\n",
        "\n",
        "  annIds = coco_train.getAnnIds(imgIds=sampleImgDict['id'], catIds=catIds_train, iscrowd=0)\n",
        "  anns = coco_train.loadAnns(annIds)\n",
        "\n",
        "\n",
        "  mask = coco_train.annToMask(anns[0])\n",
        "  for i in range(len(anns)):\n",
        "      mask = mask | coco_train.annToMask(anns[i])\n",
        "  \n",
        "  mask = Image.fromarray(mask * 255 , mode = \"L\")\n",
        "  mask.save(file_path)\n",
        "  count = count + 1\n",
        "  print(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBAlOCAg1s02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir mask_val_2014"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdcMDJGY1ui7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = 0 \n",
        "for ID in imgIds_val:\n",
        "\n",
        "  file_path = \"/content/mask_val_2014/COCO_val2014_{0:012d}.jpg\".format(ID)\n",
        "  \n",
        "  sampleImgIds = coco_val.getImgIds(imgIds = [ID])\n",
        "  sampleImgDict = coco_val.loadImgs(sampleImgIds[np.random.randint(0,len(sampleImgIds))])[0]\n",
        "\n",
        "  annIds = coco_val.getAnnIds(imgIds=sampleImgDict['id'], catIds=catIds_val, iscrowd=0)\n",
        "  anns = coco_val.loadAnns(annIds)\n",
        "\n",
        "\n",
        "  mask = coco_val.annToMask(anns[0])\n",
        "  for i in range(len(anns)):\n",
        "      mask = mask | coco_val.annToMask(anns[i])\n",
        "  \n",
        "  mask = Image.fromarray(mask * 255 , mode = \"L\")\n",
        "  mask.save(file_path)\n",
        "  \n",
        "  count = count + 1\n",
        "  print(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-OMmybC1v1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf annotations/\n",
        "!rm -rf train2014.zip\n",
        "!rm -rf val2014.zip\n",
        "!rm -rf annotations_trainval2014.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_rmAwLIezXG",
        "colab_type": "text"
      },
      "source": [
        "# Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJbmPHNceazg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "\n",
        "\n",
        "seed = 2019\n",
        "\n",
        "random.seed = seed\n",
        "np.random.seed = seed "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrV1_sQOevZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGen(keras.utils.Sequence):\n",
        "  \n",
        "  def __init__(self , path_input , path_mask , batch_size = 8 , image_size = 128):\n",
        "    \n",
        "    self.ids = os.listdir(path_input)\n",
        "    self.path_input = path_input\n",
        "    self.path_mask = path_mask\n",
        "    self.batch_size = batch_size\n",
        "    self.image_size = image_size\n",
        "    self.on_epoch_end()\n",
        "  \n",
        "  def __load__(self , id_name):\n",
        "    \n",
        "    image_path = os.path.join(self.path_input , id_name)\n",
        "    mask_path = os.path.join(self.path_mask , id_name) \n",
        "    \n",
        "    image = cv2.imread(image_path , 1) # 1 specifies RGB format\n",
        "    image = cv2.resize(image , (self.image_size , self.image_size)) # resizing before inserting to the network\n",
        "    \n",
        "    mask = cv2.imread(mask_path , -1)\n",
        "    mask = cv2.resize(mask , (self.image_size , self.image_size))\n",
        "    mask = mask.reshape((self.image_size , self.image_size , 1))\n",
        "      \n",
        "    #normalize image\n",
        "    image = image / 255.0\n",
        "    mask = mask / 255.0\n",
        "    \n",
        "    return image , mask\n",
        "  \n",
        "  def __getitem__(self , index):\n",
        "    \n",
        "    if (index + 1)*self.batch_size > len(self.ids):\n",
        "      self.batch_size = len(self.ids) - index * self.batch_size\n",
        "        \n",
        "    file_batch = self.ids[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    \n",
        "    images = []\n",
        "    masks = []\n",
        "    \n",
        "    for id_name in file_batch : \n",
        "      \n",
        "      _img , _mask = self.__load__(id_name)\n",
        "      images.append(_img)\n",
        "      masks.append(_mask)\n",
        "    \n",
        "    \n",
        "    images = np.array(images)\n",
        "    masks = np.array(masks)\n",
        "    \n",
        "    \n",
        "    return images , masks\n",
        "  \n",
        "  \n",
        "  def on_epoch_end(self):\n",
        "    pass\n",
        "  \n",
        "  \n",
        "  def __len__(self):\n",
        "    \n",
        "    return int(np.ceil(len(self.ids) / float(self.batch_size)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L3_Slh1e2vZ",
        "colab_type": "text"
      },
      "source": [
        "#UNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65_xh2VYe2M_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def down_block(\n",
        "    input_tensor,\n",
        "    no_filters,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    padding=\"same\",\n",
        "    kernel_initializer=\"he_normal\",\n",
        "    max_pool_window=(2, 2),\n",
        "    max_pool_stride=(2, 2)\n",
        "):\n",
        "    conv = Conv2D(\n",
        "        filters=no_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        activation=None,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(input_tensor)\n",
        "\n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "\n",
        "    conv = Conv2D(\n",
        "        filters=no_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        activation=None,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(conv)\n",
        "\n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    # conv for skip connection\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "\n",
        "    pool = MaxPooling2D(pool_size=max_pool_window, strides=max_pool_stride)(conv)\n",
        "\n",
        "    return conv, pool"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FaVzvm3fESd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bottle_neck(\n",
        "    input_tensor,\n",
        "    no_filters,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    padding=\"same\",\n",
        "    kernel_initializer=\"he_normal\"\n",
        "):\n",
        "    conv = Conv2D(\n",
        "        filters=no_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        activation=None,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(input_tensor)\n",
        "\n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "\n",
        "    conv = Conv2D(\n",
        "        filters=no_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        activation=None,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(conv)\n",
        "\n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "\n",
        "    return conv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSzLN6m6fGMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def up_block(    \n",
        "    input_tensor,\n",
        "    no_filters,\n",
        "    skip_connection, \n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    upsampling_factor = (2,2),\n",
        "    max_pool_window = (2,2),\n",
        "    padding=\"same\",\n",
        "    kernel_initializer=\"he_normal\"):\n",
        "    \n",
        "    \n",
        "    conv = Conv2D(\n",
        "        filters = no_filters,\n",
        "        kernel_size= max_pool_window,\n",
        "        strides = strides,\n",
        "        activation = None,\n",
        "        padding = padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(UpSampling2D(size = upsampling_factor)(input_tensor))\n",
        "    \n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv) \n",
        "    \n",
        "    \n",
        "    conv = concatenate( [skip_connection , conv]  , axis = -1)\n",
        "    \n",
        "    \n",
        "    conv = Conv2D(\n",
        "        filters=no_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        activation=None,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(conv)\n",
        "\n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "\n",
        "    conv = Conv2D(\n",
        "        filters=no_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        activation=None,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(conv)\n",
        "\n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "    \n",
        "    return conv\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LUtzcZVfG3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_block(input_tensor,\n",
        "    padding=\"same\",\n",
        "    kernel_initializer=\"he_normal\"\n",
        "):\n",
        "    \n",
        "    conv = Conv2D(\n",
        "        filters=2,\n",
        "        kernel_size=(3,3),\n",
        "        strides=(1,1),\n",
        "        activation=\"relu\",\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(input_tensor)\n",
        "    \n",
        "    \n",
        "    conv = Conv2D(\n",
        "        filters=1,\n",
        "        kernel_size=(1,1),\n",
        "        strides=(1,1),\n",
        "        activation=\"sigmoid\",\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(conv)\n",
        "    \n",
        "    \n",
        "    return conv\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOEfWxYnfJho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def UNet(input_shape = (128,128,3)):\n",
        "    \n",
        "    filter_size = [64,128,256,512,1024]\n",
        "    \n",
        "    inputs = Input(shape = input_shape)\n",
        "    \n",
        "    d1 , p1 = down_block(input_tensor= inputs,\n",
        "                         no_filters=filter_size[0],\n",
        "                         kernel_size = (3,3),\n",
        "                         strides=(1,1),\n",
        "                         padding=\"same\",\n",
        "                         kernel_initializer=\"he_normal\",\n",
        "                         max_pool_window=(2,2),\n",
        "                         max_pool_stride=(2,2))\n",
        "    \n",
        "    \n",
        "    d2 , p2 = down_block(input_tensor= p1,\n",
        "                         no_filters=filter_size[1],\n",
        "                         kernel_size = (3,3),\n",
        "                         strides=(1,1),\n",
        "                         padding=\"same\",\n",
        "                         kernel_initializer=\"he_normal\",\n",
        "                         max_pool_window=(2,2),\n",
        "                         max_pool_stride=(2,2))\n",
        "    \n",
        "    \n",
        "    \n",
        "    d3 , p3 = down_block(input_tensor= p2,\n",
        "                         no_filters=filter_size[2],\n",
        "                         kernel_size = (3,3),\n",
        "                         strides=(1,1),\n",
        "                         padding=\"same\",\n",
        "                         kernel_initializer=\"he_normal\",\n",
        "                         max_pool_window=(2,2),\n",
        "                         max_pool_stride=(2,2))\n",
        "    \n",
        "    \n",
        "    \n",
        "    d4 , p4 = down_block(input_tensor= p3,\n",
        "                         no_filters=filter_size[3],\n",
        "                         kernel_size = (3,3),\n",
        "                         strides=(1,1),\n",
        "                         padding=\"same\",\n",
        "                         kernel_initializer=\"he_normal\",\n",
        "                         max_pool_window=(2,2),\n",
        "                         max_pool_stride=(2,2))\n",
        "    \n",
        "    \n",
        "    b = bottle_neck(input_tensor= p4,\n",
        "                         no_filters=filter_size[4],\n",
        "                         kernel_size = (3,3),\n",
        "                         strides=(1,1),\n",
        "                         padding=\"same\",\n",
        "                         kernel_initializer=\"he_normal\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    u4 = up_block(input_tensor = b,\n",
        "                  no_filters = filter_size[3],\n",
        "                  skip_connection = d4,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1, 1),\n",
        "                  upsampling_factor = (2,2),\n",
        "                  max_pool_window = (2,2),\n",
        "                  padding=\"same\",\n",
        "                  kernel_initializer=\"he_normal\")\n",
        "    \n",
        "    u3 = up_block(input_tensor = u4,\n",
        "                  no_filters = filter_size[2],\n",
        "                  skip_connection = d3,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1, 1),\n",
        "                  upsampling_factor = (2,2),\n",
        "                  max_pool_window = (2,2),\n",
        "                  padding=\"same\",\n",
        "                  kernel_initializer=\"he_normal\")\n",
        "    \n",
        "    \n",
        "    u2 = up_block(input_tensor = u3,\n",
        "                  no_filters = filter_size[1],\n",
        "                  skip_connection = d2,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1, 1),\n",
        "                  upsampling_factor = (2,2),\n",
        "                  max_pool_window = (2,2),\n",
        "                  padding=\"same\",\n",
        "                  kernel_initializer=\"he_normal\")\n",
        "    \n",
        "    \n",
        "    u1 = up_block(input_tensor = u2,\n",
        "                  no_filters = filter_size[0],\n",
        "                  skip_connection = d1,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1, 1),\n",
        "                  upsampling_factor = (2,2),\n",
        "                  max_pool_window = (2,2),\n",
        "                  padding=\"same\",\n",
        "                  kernel_initializer=\"he_normal\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    output = output_block(input_tensor=u1 , \n",
        "                         padding = \"same\",\n",
        "                         kernel_initializer= \"he_normal\")\n",
        "    \n",
        "    model = keras.models.Model(inputs = inputs , outputs = output)\n",
        "    \n",
        "    \n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVbsBQnJfOlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = UNet(input_shape = (128,128,3))\n",
        "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpPfRQyrfVtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 128 \n",
        "epochs = 10\n",
        "batch_size = 8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7uP2BG9gX9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen = DataGen(path_input = \"/content/train2014\" , path_mask = \"/content/mask_train_2014/\" , batch_size = batch_size , image_size = image_size)\n",
        "val_gen = DataGen(path_input =  \"/content/val2014\", path_mask =  \"/content/mask_val_2014\", batch_size = batch_size , image_size = image_size)\n",
        "\n",
        "\n",
        "train_steps =  len(os.listdir( \"/content/train2014\"))/batch_size\n",
        "\n",
        "\n",
        "model.fit_generator(train_gen , validation_data = val_gen , steps_per_epoch = train_steps , epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykqwnhtNhtFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = val_gen.__getitem__(4)\n",
        "result = model.predict(x)\n",
        "\n",
        "result = result > 0.5\n",
        "\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(np.reshape(y[0]*255, (image_size, image_size)), cmap=\"gray\")\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.imshow(np.reshape(result[0]*255, (image_size, image_size)), cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQqf0lvjk-jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}